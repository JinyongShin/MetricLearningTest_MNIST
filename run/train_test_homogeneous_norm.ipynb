{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, ConcatDataset\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import umap.umap_ as umap\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import random\n",
    "seed = 777\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "import os\n",
    "os.environ[\"PYTHONHASHSEED\"]=str(seed)\n",
    "torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "torch.backends.cudnn.benchmark = True  # type: ignore\n",
    "\n",
    "import loader.load_from_h5 as loadh5\n",
    "from model.model_binary import MyModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_la = 0\n",
    "\n",
    "data_file = glob.glob('../data/normal*.h5')\n",
    "\n",
    "feature = loadh5.FeatureDataset(data_file).get_array()\n",
    "label = loadh5.FeatureDataset(data_file).get_label()\n",
    "\n",
    "target_feature = torch.FloatTensor(feature[label==target_la])\n",
    "target_label = torch.FloatTensor(label[label==target_la])\n",
    "\n",
    "norm_ds = TensorDataset(target_feature,target_label)\n",
    "\n",
    "Anomaly_data_file = glob.glob('../data/Anomaly_dataset.h5')\n",
    "ano_ds = loadh5.FeatureDataset(Anomaly_data_file).get_dataset(split_type='all')\n",
    "\n",
    "#ds = ConcatDataset([norm_ds,ano_ds])\n",
    "\n",
    "length = [int(len(norm_ds)*0.7),int(len(norm_ds)*0.2)]\n",
    "length.append((len(norm_ds)-sum(length)))\n",
    "NtrnSet,NvalSet,NtstSet = torch.utils.data.random_split(norm_ds,length)\n",
    "\n",
    "length = [int(len(ano_ds)*0.7),int(len(ano_ds)*0.2)]\n",
    "length.append((len(ano_ds)-sum(length)))\n",
    "AtrnSet,AvalSet,AtstSet = torch.utils.data.random_split(ano_ds,length)\n",
    "\n",
    "trnSet = ConcatDataset([NtrnSet,AtrnSet])\n",
    "valSet = ConcatDataset([NvalSet,AvalSet])\n",
    "tstSet = ConcatDataset([NtstSet,AtstSet])\n",
    "\n",
    "train_loader = DataLoader(trnSet, batch_size = 64, shuffle = True)\n",
    "val_loader = DataLoader(valSet, batch_size = 64, shuffle=False)\n",
    "test_loader = DataLoader(valSet, batch_size = 64, shuffle=False)\n",
    "\n",
    "# train_loader = loadh5.FeatureDataset(data_file).get_dataloader(split_type='training')\n",
    "# val_loader = loadh5.FeatureDataset(data_file).get_dataloader(split_type='validation')\n",
    "# test_loader = loadh5.FeatureDataset(data_file).get_dataloader(split_type='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_la = 0\n",
    "\n",
    "# data_file = glob.glob('../data/normal*.h5')\n",
    "# test_loader = loadh5.FeatureDataset(data_file).get_dataloader(split_type='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel().to('cuda')\n",
    "\n",
    "c_criterion = nn.NLLLoss()\n",
    "t_criterion = nn.TripletMarginLoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=1e-3)\n",
    "\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "tst_embedded = []\n",
    "tst_y = []\n",
    "for x, y in test_loader:\n",
    "    x = Variable(x.float()).to('cuda')\n",
    "    embedded = model.embedding(x.view(-1,784)).detach().cpu()\n",
    "    tst_embedded.append(embedded)\n",
    "    tst_y.append(y)\n",
    "tst_embedded = torch.cat(tst_embedded)\n",
    "tst_y = torch.cat(tst_y)\n",
    "#print(torch.unique(tst_y))\n",
    "#print(tst_embedded.shape,tst_y.shape)\n",
    "hle = umap.UMAP(random_state=0,metric='euclidean',n_components=2,n_neighbors=20,min_dist=0).fit_transform(tst_embedded)\n",
    "c_lst = [plt.cm.nipy_spectral(a) for a in np.linspace(0.0, 1.0, len(np.unique(tst_y)))]\n",
    "plt.figure(figsize=(10,10))\n",
    "for idx,label in enumerate(torch.unique(tst_y)):\n",
    "    i = int(label)\n",
    "    plt.scatter(hle[tst_y==i,0],hle[tst_y==i,1],label=i,color=c_lst[idx])\n",
    "plt.legend(loc='best')\n",
    "plt.title('UMAP 2D Before Training')\n",
    "plt.savefig(f'../result/model_hom_beforeTraining.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss=[]\n",
    "val_loss = []\n",
    "best_acc = 0\n",
    "for epoch in tqdm(range(1,epochs+1)):\n",
    "#for epoch in range(1,epochs+1):\n",
    "    model.train()\n",
    "    b_loss=[]\n",
    "    for x ,y in train_loader:\n",
    "        #print(y)\n",
    "        for y_idx, y_i in enumerate(y):\n",
    "            if y_i == target_la:\n",
    "                y[y_idx] = 0\n",
    "            else:\n",
    "                y[y_idx] = 1\n",
    "        #print(y)\n",
    "        \n",
    "        x = Variable(x.float()).to('cuda')\n",
    "        y = Variable(y.type(torch.LongTensor)).to('cuda')\n",
    "        \n",
    "        out = model(x)\n",
    "        embedded = model.embedding(x.view(-1,784))\n",
    "\n",
    "        triplet_tensor = []\n",
    "        triplet_label = []\n",
    "        \n",
    "        anchor_x, anchor_y = embedded[y==0], y[y==0]\n",
    "        positive_x, positive_y = embedded[y==0], y[y==0]\n",
    "        negative_x, negative_y = embedded[y!=0], y[y!=0]\n",
    "        #print(anchor.shape,positive.shape,negative.shape)\n",
    "        a_ind = torch.arange(0,len(anchor_x))\n",
    "        p_ind = torch.arange(0,len(positive_x))\n",
    "        n_ind = torch.arange(0,len(negative_x))\n",
    "        triplet_ind = torch.cartesian_prod(a_ind,p_ind,n_ind)\n",
    "        #print(triplet_ind.shape)\n",
    "        \n",
    "        for a,p,n in triplet_ind:\n",
    "            if a != p:\n",
    "                #print(anchor_x[a].shape,positive_x[p].shape,negative_x[n].shape)\n",
    "                triplet_tensor.append(torch.stack([anchor_x[a],positive_x[p],negative_x[n]]))\n",
    "                triplet_label.append(torch.stack([anchor_y[a],positive_y[p],negative_y[n]]))\n",
    "                #break\n",
    "        \n",
    "        if len(triplet_tensor)==0:\n",
    "            continue\n",
    "        else:\n",
    "            triplet_tensor = torch.stack(triplet_tensor)\n",
    "            triplet_label = torch.stack(triplet_label)\n",
    "            #print(triplet_tensor.shape)\n",
    "            \n",
    "            anchor = triplet_tensor[:,0]\n",
    "            positive = triplet_tensor[:,1]\n",
    "            negative = triplet_tensor[:,2]\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            #print(out.shape,y.shape)\n",
    "            classification_loss = c_criterion(out,y)\n",
    "            triplet_loss = t_criterion(anchor,positive,negative)\n",
    "            loss = classification_loss + triplet_loss\n",
    "            b_loss.append(loss.cpu().item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    train_loss.append(np.array(b_loss).mean())\n",
    "    \n",
    "    model.eval()\n",
    "    b_loss=[]\n",
    "    with torch.no_grad():\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for x,y in val_loader:\n",
    "            for y_idx, y_i in enumerate(y):\n",
    "                if y_i == target_la:\n",
    "                    y[y_idx] = 0\n",
    "                else:\n",
    "                    y[y_idx] = 1\n",
    "            \n",
    "            x = Variable(x.float()).to('cuda')\n",
    "            y = Variable(y.type(torch.LongTensor)).to('cuda')\n",
    "            \n",
    "            out = model(x)\n",
    "            \n",
    "            out_sm = F.softmax(out,dim=1).cpu()\n",
    "            predict = (F.softmax(out_sm,dim=1)).argmax(1).cpu()\n",
    "            \n",
    "            total += y.size(0)\n",
    "            correct += (predict ==y.cpu()).sum().item()\n",
    "            \n",
    "            loss = c_criterion(out,y)\n",
    "            b_loss.append(loss.cpu().item())\n",
    "    val_loss.append(np.array(b_loss).mean())\n",
    "    acc = 100 * (correct / total)\n",
    "    if best_acc < acc:\n",
    "        best_acc = acc\n",
    "        best_epoch = epoch\n",
    "        best_state_dict = model.state_dict()\n",
    "        torch.save(best_state_dict,'../result/model_hom_best.pth')\n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "        print(\"Validation Accuracy\",acc,'at Epoch',epoch)\n",
    "        torch.save(best_state_dict,f'../result/model_hom_{epoch}epoch.pth')\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            tst_embedded = []\n",
    "            tst_y = []\n",
    "            for x, y in test_loader:\n",
    "                x = Variable(x.float()).to('cuda')\n",
    "                embedded = model.embedding(x.view(-1,784)).detach().cpu()\n",
    "                tst_embedded.append(embedded)\n",
    "                tst_y.append(y)\n",
    "            tst_embedded = torch.cat(tst_embedded)\n",
    "            tst_y = torch.cat(tst_y)\n",
    "            #print(tst_embedded.shape,tst_y.shape)\n",
    "            hle = umap.UMAP(random_state=0,metric='euclidean',n_components=2,n_neighbors=20,min_dist=0).fit_transform(tst_embedded)\n",
    "            c_lst = [plt.cm.nipy_spectral(a) for a in np.linspace(0.0, 1.0, len(np.unique(tst_y)))]\n",
    "            plt.figure(figsize=(10,10))\n",
    "            for idx,label in enumerate(torch.unique(tst_y)):\n",
    "                i = int(label)\n",
    "                plt.scatter(hle[tst_y==i,0],hle[tst_y==i,1],label=i,color=c_lst[idx])\n",
    "            plt.legend(loc='best')\n",
    "            plt.title('UMAP 2D at Epoch'+str(epoch))\n",
    "            plt.savefig(f'../result/model_hom_{epoch}epoch.png')\n",
    "            plt.show()\n",
    "            plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss,label='train loss')\n",
    "plt.plot(val_loss,label='validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Validation Accuracy Epoch\",best_epoch)\n",
    "print(\"Best Validation Accuracy(%)\",best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('../result/model_hom_best.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "tst_embedded = []\n",
    "tst_y = []\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        x = Variable(x.float()).to('cuda')\n",
    "        embedded = model.embedding(x.view(-1,784)).detach().cpu()\n",
    "        tst_embedded.append(embedded)\n",
    "        tst_y.append(y)\n",
    "            \n",
    "tst_embedded = torch.cat(tst_embedded)\n",
    "tst_y = torch.cat(tst_y)\n",
    "#print(tst_embedded.shape,tst_y.shape)\n",
    "hle = umap.UMAP(random_state=0,metric='euclidean',n_components=2,n_neighbors=20,min_dist=0).fit_transform(tst_embedded)\n",
    "c_lst = [plt.cm.nipy_spectral(a) for a in np.linspace(0.0, 1.0, len(np.unique(tst_y)))]\n",
    "plt.figure(figsize=(10,10))\n",
    "for idx,label in enumerate(torch.unique(tst_y)):\n",
    "    i = int(label)\n",
    "    plt.scatter(hle[tst_y==i,0],hle[tst_y==i,1],label=i,color=c_lst[idx])\n",
    "plt.legend(loc='best')\n",
    "plt.title('UMAP 2D at Best epoch')\n",
    "plt.savefig(f'../result/model_hom_{epoch}epoch.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = []\n",
    "pred = []\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        #print(y)\n",
    "        for y_idx, y_i in enumerate(y):\n",
    "            #print(y.shape)\n",
    "            if y_i == target_la:\n",
    "                y[y_idx] = 0\n",
    "            else:\n",
    "                y[y_idx] = 1\n",
    "        #print(y)\n",
    "        x = Variable(x.float()).to('cuda')\n",
    "        y = Variable(y.type(torch.LongTensor)).to('cuda')\n",
    "        out = model(x)\n",
    "                \n",
    "        out_sm = F.softmax(out,dim=1).cpu()\n",
    "        predict = (F.softmax(out_sm,dim=1)).argmax(1).cpu()\n",
    "        label.append(y.cpu().numpy())\n",
    "        pred.append(predict.cpu().numpy())\n",
    "label = np.concatenate(label)\n",
    "pred = np.concatenate(pred)\n",
    "print(label.shape)\n",
    "print(pred.shape)\n",
    "confusion_mat = confusion_matrix(label,pred)\n",
    "print(confusion_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = []\n",
    "pred = []\n",
    "with torch.no_grad():\n",
    "    for x, y in val_loader:\n",
    "        #print(y)\n",
    "        for y_idx, y_i in enumerate(y):\n",
    "            #print(y.shape)\n",
    "            if y_i == target_la:\n",
    "                y[y_idx] = 0\n",
    "            else:\n",
    "                y[y_idx] = 1\n",
    "        #print(y)\n",
    "        x = Variable(x.float()).to('cuda')\n",
    "        y = Variable(y.type(torch.LongTensor)).to('cuda')\n",
    "        out = model(x)\n",
    "                \n",
    "        out_sm = F.softmax(out,dim=1).cpu()\n",
    "        predict = (F.softmax(out_sm,dim=1)).argmax(1).cpu()\n",
    "        label.append(y.cpu().numpy())\n",
    "        pred.append(predict.cpu().numpy())\n",
    "label = np.concatenate(label)\n",
    "pred = np.concatenate(pred)\n",
    "print(label.shape)\n",
    "print(pred.shape)\n",
    "confusion_mat = confusion_matrix(label,pred)\n",
    "print(confusion_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('jishin')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8e30b09244de0881d2b8123c4ae6f9330a23abfd8a67ea383a863f488e9b4eda"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
